---
title: "CTB Modeling"
author: "Rita Ludwig, John Flournoy"
date: "`r Sys.time()`"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nlme)
#Note that the repository currently does not contain the raw
#mCTB responses needed in this script.

data_dir_base <- './'

plot_mctb_responses <- function(slice_of_data, adj.pratio = TRUE){
  slice_of_data$pratio_group <- factor(
    case_when(slice_of_data$pratio > 1.2 ~ 1,
              slice_of_data$pratio > 1 ~ 2,
              slice_of_data$pratio == 1 ~ 3),
    levels = c(1, 2, 3), 
    labels = c('High', 'Low', 'No ratio'))
  
  if(adj.pratio){
    slice_of_data$sooner_choice_for_plot <- 
      slice_of_data$sooner_choice*slice_of_data$pratio
  } else {
    slice_of_data$sooner_choice_for_plot <- 
      slice_of_data$sooner_choice
  }
  
  aplot <- ggplot(slice_of_data, 
         aes(x = (k - sooner_date_weeks*7)/7, 
             y = sooner_choice_for_plot,
             alpha = pratio)) + 
    geom_line(stat = 'smooth', method = 'lm', color = '#555555',
              aes(group = pratio_group,
                  linetype = pratio_group)) + 
    geom_point(position = position_jitter(width = .075, height = .01),
               size = 2) + 
    scale_alpha_continuous(range = c(.25, 1)) + 
    facet_grid(factor(t0)~subject_id, 
               labeller = labeller(
                 subject_id = label_value,
                 `factor(t0)` = as_labeller(c(`0` = 'Sooner: in 5 weeks', 
                                              `1` = 'Sooner: today')))) + 
    labs(x = 'Number of weeks delay', y = 'Sooner choice amount', 
         alpha = 'Price ratio', linetype = 'Price ratio bin') + 
    coord_cartesian(x = c(3, 12), y = c(-10, 30)) + 
    scale_x_continuous(breaks = c(5,9)) + 
    scale_y_continuous(breaks = c(0, 10, 20)) + 
    NULL
  return(aplot)
}

CachedFit <- function(expr, rds_filename, save_only = F){
  if(file.exists(rds_filename) && !save_only){
    message('Loading...')
    theFit <- readRDS(rds_filename)
  } else if(file.exists(rds_filename) && save_only){
      message('save_only is TRUE but file already exists (returning NULL)')
      return(NULL)
  } else {
    message('Evaluating... (save_only = ', save_only, ')')
    theFit <- try(eval(expr))
    message('Writing result to ', rds_filename)
    saveRDS(theFit, rds_filename)
  }
  if(save_only){
      if(any('try-error' %in% class(theFit))){
          return(theFit)
      } else {
          return(TRUE)
      }
  } else {
      return(theFit)
  }
}
```

We will fit a multi-level non-linear (on the parameters) regression model to the data from the sample. The regression takes the form: 

$$
\text{sooner_choice}=\frac{\text{endowment_later}\cdot(b^{t_0}d^k\text{pratio})^{\frac{1}{a-1}}}{1+\text{pratio}\cdot(b^{t_0}d^k\text{pratio})^{\frac{1}{a-1}}}
$$
where $\text{endowment_later}=20$.

In R, this looks like the following formula for the population-level parameters (i.e., the fixed effects):

```
sooner_choice ~ ( endowment_later * (b^t0 * d^k * pratio)^(1/(a-1)) ) / ( 1+pratio * (b^t0 * d^k * pratio)^(1/(a-1)) )
```

We start by importing the data and ensuring that it contains all of the information for each trial we need. For example, we need to add columns that specify the delay period for each trial.

```{r data setup}
mctb_data_ <- utils::read.table(file.path(data_dir_base, 'mCTB_kit/data.txt'), 
                         header = TRUE, 
                         na.strings = '.')

mctb_data_l <- stats::reshape(mctb_data_, 
                              varying = paste0('c', 1:24),
                              v.names = 'c',
                              timevar = 'budget_number',
                              times = 1:24, 
                              direction = 'long')

mctb_design <- read.table(file.path(data_dir_base, 'mCTB_kit/instrument_details.txt'),
                     header = TRUE)

mctb_data <- merge(mctb_data_l, mctb_design, 
                   by = 'budget_number', 
                   all.x = TRUE, all.y = TRUE)

head(mctb_data)
```

We will also take this opportunity to examine missing reponses.

```{r missing, fig.width = 4, fig.height= 3}
n_missing_responses <- dplyr::summarize(group_by(mctb_data, subject_id),
                                        n_missing = sum(is.na(c)),
                                        p_missing = n_missing/n())
plot(n_missing_responses$subject_id, n_missing_responses$p_missing, 
     type = 'h', xlab = 'Participant ID', ylab = 'Proportion missing responses',
     ylim = c(0,1))

knitr::kable(filter(n_missing_responses, p_missing > 0),
             digits = 2,
             caption = paste0('Proportion missing by participant. Total N with missing data = ',
                              sum(n_missing_responses$p_missing > 0)))
```

Here, we define some trial-level predictors. t0 defines whether the soonest choice is today or also in the future. We modify k so that it is in terms of days, rather than weeks. We also calculate the price ratio, which is just the ratio of the later reward and sooner reward.

```{r choiset variable creation}
mctb_data$t0 <- as.numeric(mctb_data$sooner_date_weeks == 0)
mctb_data$k <- 7 * mctb_data$delay_weeks
mctb_data$k_w <- mctb_data$delay_weeks
mctb_data$pratio <- mctb_data$endowment_later / mctb_data$endowment_soon
```

Here we calculate the possible value choices the participant saw for each trial.

```{r value definition}
for(j in 1:6){
  mctb_data[paste0('soon_', j)] <- (20/as.vector(mctb_data$pratio)) - (j-1) * (20/as.vector(mctb_data$pratio)) / 5
  mctb_data[paste0('late_', j)] <- (j-1) * 4
}

mctb_data$soon_6 <- 0
```

Finally, based on the particpant's response, 1-6, we create a column that contains the amount of money they choose to receive at the soonest possible time. If they choose option 6, to receive the full \$20 at the later time, they always receive \$0 at the sooner time.

```{r choice association}
#Create a new variable with a value that corresponds to the response option
#chose in `mctb_data$c`
mctb_data$sooner_choice <- apply(
  mctb_data, 1, #for every row in mctb_data
  function(a_row){ 
    #write the name of the column to get the choice value from
    choice_col <- paste0('soon_', a_row['c']) 
    #get the choice value
    sc <- a_row[choice_col] 
    #if it's null, return NA, otherwise return the choice value
    return( ifelse(is.null(sc), NA, sc)) 
  })
```

Exclusion criteria are specified:

>If participants miss greater than or equal to 50% of items on a personality scale, they will be coded as missing a score for that scale and not be included in analyses involving that scale. Due to the nature of the CTB task, participants who miss more than one item per timeframe pair will be coded as missing and excluded from analysis. Finally, participants who did not self-report household income will be excluded from analysis.


As we saw above, some participants are missing more than one response on the CTB task. No one did not report income. Some participants failed to answer >50% of items on a personality scale.

```{r}
scale_data <- read_csv('ScoredScales_JRP_poverty.csv')

scale_data_missing <- select(scale_data, contains('score'), subID) %>%
  filter_at(.vars = vars(-subID), any_vars(is.na(.)))

missing_ids <- full_join(filter(n_missing_responses, n_missing > 0),
                         scale_data_missing,
                         by = c('subject_id' = 'subID'))

mctb_data <- anti_join(mctb_data, missing_ids,
                       by = 'subject_id')
```

Total number of excluded IDs is `r dim(missing_ids)[1]`, or `r round(dim(missing_ids)[1]/dim(scale_data)[1]*100,1)`%.

We use fixed-effects non-linear least-squares as a first pass on the data and to set starting values for the individual-level analyses that will assist the multi-level estimation.

```{r non-linear least squares aggregate parameter estimation one}
sd_of_soonerchoice <- sd(mctb_data$sooner_choice, na.rm = TRUE)

#scale the outcome
mctb_data$sooner_choice_scaled <- mctb_data$sooner_choice / sd_of_soonerchoice
mctb_data$endowment_later_scaled <- mctb_data$endowment_later / sd_of_soonerchoice

a_start <- 0.90
b_start <- 1
d_start <- 0.999

nls_ctb_model <- nls(sooner_choice ~ 
                       ( endowment_later * (b^t0 * d^k * pratio)^(1/(a-1)) ) / 
                       ( 1+pratio * (b^t0 * d^k * pratio)^(1/(a-1)) ),
          mctb_data, 
          start = list(a = a_start, 
                       b = b_start, 
                       d = d_start))

knitr::kable(broom::tidy(nls_ctb_model), digits = 4)

##STORE MODEL PARAMS##
alpha_nls <- summary(nls_ctb_model)$coefficients[1]
beta_nls<- summary(nls_ctb_model)$coefficients[2]
delta_nls <- summary(nls_ctb_model)$coefficients[3] 
mctb_data$alpha_nls <- alpha_nls
mctb_data$beta_nls <- beta_nls
mctb_data$delta_nls <- delta_nls
```

We can interpret these values as follows: $a$ is considerably less than 1, indicating overall risk-aversion. In other words, people are willing to pay a cost, with the delay held equal, just for getting money sooner rather than waiting. The parameter $b < 1$ indicates people discount even a bit more by a factor of $b = `r round(beta_nls,4)`$ if they can get the sooner reward today, rather than waiting five weeks. In other words, for a constant delay of 5 weeks, they discount at a rate $d=`r round(delta_nls,4)`$ per day multiplied by $`r round(beta_nls,4)`$ if they get the sooner reward today (the sooner discount for a five week delay is $`r round(delta_nls,4)`^{5\times7} = `r round(delta_nls^(5*7),4)`$, but if the sooner reward is today, it's $`r round(beta_nls,4)` \times `r round(delta_nls,4)`^{5\times7} = `r round(beta_nls*delta_nls^(5*7),4)`$).

If we apply this to the full equation above, we can find the sooner payout that, combined with the portion of the payout received later, is equivalent to a \$20 later payout for a participant with these parameter values (if the sooner payout is received today, for a price ratio of, say, 20/16 = `r 20/16`):

```{r}
sooner_choice_calc <- (20 * (beta_nls*delta_nls^(7*5)*1.25)^(1/(alpha_nls-1)) )/
  ( 1 + 1.25 * (beta_nls*delta_nls^(7*5)*1.25)^(1/(alpha_nls-1)) )
```

$$
`r round(sooner_choice_calc,2)` = \frac{20\cdot(`r round(beta_nls, 4)`^{1}\cdot `r round(delta_nls, 4)`^{7\times5}\cdot1.25)^{\frac{1}{`r round(alpha_nls, 4)`-1}}}{1+1.25\cdot(`r round(beta_nls, 4)`^{1}\cdot `r round(delta_nls, 4)`^{7\times5}\cdot1.25)^{\frac{1}{`r round(alpha_nls, 4)`-1}}}
$$

So, these population parameters suggest that someone will be just as happy getting \$`r round(sooner_choice_calc,2)` today and \$`r round(20-(1.25*sooner_choice_calc),2)` (for a total of \$`r round(sooner_choice_calc + 20-(1.25*sooner_choice_calc),2)`) later as they would to receive the full $20 later.

Another way of expressing the discounting variable is in terms of a monthly discount rate. This works out to be the amount someone gives up to avoid a month-long delay as a percentage of the total they receive immediately.

```{r monthly discount rate}
(a_monthly_rate <- delta_nls^(-30) - 1)
```

# Individual-level parameters

Find the cases that have no meaningful variability in their responses. We exclude trials where you could receive \$20 sooner or \$20 later.

```{r}
odd_cases <- group_by(mctb_data, subject_id) %>%
  filter(soon_1 != late_6) %>%
  summarize(
    no_interior = case_when(
      any(c %in% 2:5) ~ FALSE,
      all(c %in% c(1,6)) ~ TRUE,
      TRUE ~ NA
    ),
    no_variance = case_when(
      all(c == 1) ~ TRUE,
      all(c == 6) ~ TRUE,
      TRUE ~ FALSE
    ))

print(paste0('All cases that have no variance also have no interior solutions: ', 
             all(odd_cases$no_interior[odd_cases$no_variance])))

#View(odd_cases)

table(odd_cases[,2:3])


```

This indicates that 345 participants always answer either sooner or later exclusively (excluding the \$20 now versus \$20 later trials). 533 participants use the interior options, and 201 participants just switch between taking everything sooner, or everything later.

```{r message = T, warning = T, error = F}
mctb_form_char <- 'sooner_choice_scaled ~ 
    ( endowment_later_scaled * (b^t0 * d^k_w * pratio)^(1/(a-1)) ) / 
    ( 1+pratio * (b^t0 * d^k_w * pratio)^(1/(a-1)) )'

mctb_nlslist <- nlsList(
  sooner_choice_scaled ~ 
    ( endowment_later_scaled * (b^t0 * d^k_w * pratio)^(1/(a-1)) ) / 
    ( 1+pratio * (b^t0 * d^k_w * pratio)^(1/(a-1)) ) | subject_id, 
  data = select(mctb_data,
                t0, k_w, pratio, subject_id,
                sooner_choice_scaled, endowment_later_scaled), 
  start = c(a=alpha_nls,b=beta_nls, d=delta_nls),
  control = list(maxiter = 5000, minFactor = 1/2^30, tol = 1e-1))

converged <- lapply(mctb_nlslist,
                    function(amod) !is.null(amod))

converged_df <- data_frame(subject_id = as.numeric(names(converged)), 
                  nlslist_converged = unlist(converged),
                  nlslist = 1)

mctb_data_diagnostics <- left_join(
  left_join(mctb_data, odd_cases,
            by = 'subject_id'),
  converged_df[,-3],
  by = 'subject_id')
```



```{r fig.width=10, fig.height=4}
ggplot2::theme_set(ggplot2::theme_minimal())
plot_mctb_responses(
  filter(mctb_data, subject_id %in% 
           c(converged_df$subject_id[converged_df$nlslist_converged][1:3],
             converged_df$subject_id[!converged_df$nlslist_converged][1:3])),
  adj.pratio = TRUE)
```

```{r}
mctb_nlme.nlslist <- nlme.nlsList(model = mctb_nlslist,
                                  random = b + d ~ 1,
                                  groups = ~subject_id,
                                  method = 'ML')
summary(mctb_nlme.nlslist)
```

```{r}
qplot(sample = residuals(mctb_nlme.nlslist)/sd(residuals(mctb_nlme.nlslist)), 
      geom = c('qq', 'abline'), 
      main = "Q-Q plot for conditional residuals")

qplot(sample = ranef(mctb_nlme.nlslist)$b/sd(ranef(mctb_nlme.nlslist)$b), 
      geom = c('qq', 'abline'), 
      main = "Q-Q plot for  random b")

qplot(sample = ranef(mctb_nlme.nlslist)$d/sd(ranef(mctb_nlme.nlslist)$d), 
      geom = c('qq', 'abline'), 
      main = "Q-Q plot for  random d")

qplot(x = predict(mctb_nlme.nlslist), y = residuals(mctb_nlme.nlslist),
      geom = c('jitter', 'smooth'), width = .05, height = .05)

qplot(x = predict(mctb_nlme.nlslist), y = sqrt(abs(scale(residuals(mctb_nlme.nlslist)))),
      geom = c('jitter', 'smooth'), width = .05, height = .05)
plot(mctb_nlme.nlslist, subject_id ~ resid(.))
```


```{r fig.width=20, fig.height=40, eval = FALSE}
plot(mctb_nlme.nlslist, sooner_choice_scaled ~ fitted(.) | subject_id)
```

```{r}
mctb_nlme.nlslist_coef_df <- as.data.frame(coef(mctb_nlme.nlslist))
mctb_nlme.nlslist_coef_df$subject_id <- as.numeric(rownames(mctb_nlme.nlslist_coef_df))

mctb_data_model_info <- left_join(mctb_data_diagnostics,
                                  mctb_nlme.nlslist_coef_df,
                                  by = 'subject_id')

mctb_model_results <- distinct(mctb_data_model_info,
                               subject_id, a, b, d, 
                               no_interior, no_variance, nlslist_converged)
write_csv(mctb_model_results, 
          path = file.path(data_dir_base, 
                           'Data/mctb_model_parameters.csv'))
```

```{r}
mctb_pars_and_flags <- distinct(mctb_data_model_info, 
                  a, b, d, 
                  no_interior, no_variance, nlslist_converged,
                  subject_id)

flag_summaries <- group_by(mctb_pars_and_flags,
                           no_interior, no_variance) %>%
  summarize(a = mean(a, na.rm = T),
            b = mean(b, na.rm = T),
            d = mean(d, na.rm = T),
            n = n())

knitr::kable(bind_rows(flag_summaries,
                       as.data.frame(t(fixef(mctb_nlme.nlslist)))), digits = 4)
```


```{r}
for(avar in list(list('b', .05), list('d', .005))) {
  print(ggplot(mctb_pars_and_flags,
         aes_string(x = avar[[1]], 
             group = 'nlslist_converged',
             fill = 'nlslist_converged')) + 
    geom_vline(xintercept = 1) +
    geom_histogram(position = position_dodge(),
                   aes(y = ..count..),
                   binwidth = avar[[2]]) + 
    facet_grid(no_interior ~ no_variance,
               labeller = labeller(
                 no_interior = as_labeller(c('TRUE' = 'No interior choices',
                                             'FALSE' = 'Has interior choices')),
                 no_variance = as_labeller(c('TRUE' = 'No choice variance',
                                             'FALSE' = 'Has choice variance'))),
               as.table = TRUE) + 
      labs(x = paste0('Parameter ', avar[[1]]),
           fill = 'Single-subject\nNLS model\nconverged?') + 
      theme_minimal())
}
```

Participants who have very low d values:

```{r eval = T}
plot_small_d_sids <- unlist(distinct(filter(mctb_data_model_info, 
                                          d < .94, !no_variance),
                                   subject_id))
for(i in unique((1:23 -1) %/% 6)){
  last_index <- ifelse(i*6 < length(plot_small_d_sids),
                       (i+1)*6,
                       length(plot_small_d_sids))
  first_index <- i*6 + 1
  print(plot_mctb_responses(filter(
    mctb_data_model_info, 
    subject_id %in% plot_small_d_sids[first_index:last_index]))
    +theme_minimal())
}
```


## Plotting all the choices

```{r fig.height=3, fig.width=8, eval = FALSE}
set.seed(2134123)
theme_set(theme_minimal())

mctb_sample_ids <- distinct(mctb_data, subject_id) %>%
  mutate(plot_group = (1:n()-1) %/% 5)

for(g in 0:max(mctb_sample_ids$plot_group)){
  mctb_data_sample <- left_join(
    filter(mctb_sample_ids, plot_group == g),
           mctb_data, by = 'subject_id')
  
  aplot <- plot_mctb_responses(mctb_data_sample)
  print(aplot)
}
```


### Parameter-behavior correlation check

```{r}
behavior_summary <- group_by(mctb_data, t0, subject_id) %>%
  summarize(sooner_choice = mean(sooner_choice)) %>%
  gather(key, value, -subject_id, -t0) %>%
  unite(key, key, t0) %>%
  spread(key, value) %>%
  mutate(mean_choice = (sooner_choice_0 + sooner_choice_1)/2,
         diff_choice = sooner_choice_1 - sooner_choice_0)

compare_df <- left_join(mctb_model_results, behavior_summary)

plot(compare_df$mean_choice, compare_df$d)
plot(compare_df$diff_choice, compare_df$b)
```

The above plots indicate a reasonable mapping of individual-level parameter values to the observed behavior.